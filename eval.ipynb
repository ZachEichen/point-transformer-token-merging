{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.dataset.modelnet40 import load_modelnet40\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "airplane (1/40): 100%|██████████| 626/626 [00:00<00:00, 382188.40it/s]\n",
      "bathtub (2/40): 100%|██████████| 106/106 [00:00<00:00, 373296.58it/s]\n",
      "bed (3/40): 100%|██████████| 515/515 [00:00<00:00, 448146.59it/s]\n",
      "bench (4/40): 100%|██████████| 173/173 [00:00<00:00, 461293.45it/s]\n",
      "bookshelf (5/40): 100%|██████████| 572/572 [00:00<00:00, 356114.28it/s]\n",
      "bottle (6/40): 100%|██████████| 335/335 [00:00<00:00, 508906.86it/s]\n",
      "bowl (7/40): 100%|██████████| 64/64 [00:00<00:00, 454205.51it/s]\n",
      "car (8/40): 100%|██████████| 197/197 [00:00<00:00, 454998.84it/s]\n",
      "chair (9/40): 100%|██████████| 889/889 [00:00<00:00, 511837.51it/s]\n",
      "cone (10/40): 100%|██████████| 167/167 [00:00<00:00, 457809.65it/s]\n",
      "cup (11/40): 100%|██████████| 79/79 [00:00<00:00, 374406.80it/s]\n",
      "curtain (12/40): 100%|██████████| 138/138 [00:00<00:00, 516798.17it/s]\n",
      "desk (13/40): 100%|██████████| 200/200 [00:00<00:00, 495195.28it/s]\n",
      "door (14/40): 100%|██████████| 109/109 [00:00<00:00, 417896.83it/s]\n",
      "dresser (15/40): 100%|██████████| 200/200 [00:00<00:00, 540851.58it/s]\n",
      "flower_pot (16/40): 100%|██████████| 149/149 [00:00<00:00, 483708.43it/s]\n",
      "glass_box (17/40): 100%|██████████| 171/171 [00:00<00:00, 232638.98it/s]\n",
      "guitar (18/40): 100%|██████████| 155/155 [00:00<00:00, 1448.05it/s]\n",
      "keyboard (19/40): 100%|██████████| 145/145 [00:00<00:00, 503455.36it/s]\n",
      "lamp (20/40): 100%|██████████| 124/124 [00:00<00:00, 443009.96it/s]\n",
      "laptop (21/40): 100%|██████████| 149/149 [00:00<00:00, 522971.80it/s]\n",
      "mantel (22/40): 100%|██████████| 284/284 [00:00<00:00, 511676.26it/s]\n",
      "monitor (23/40): 100%|██████████| 465/465 [00:00<00:00, 550946.71it/s]\n",
      "night_stand (24/40): 100%|██████████| 200/200 [00:00<00:00, 494903.13it/s]\n",
      "person (25/40): 100%|██████████| 88/88 [00:00<00:00, 492131.67it/s]\n",
      "piano (26/40): 100%|██████████| 231/231 [00:00<00:00, 464915.65it/s]\n",
      "plant (27/40): 100%|██████████| 240/240 [00:00<00:00, 527585.41it/s]\n",
      "radio (28/40): 100%|██████████| 104/104 [00:00<00:00, 442850.37it/s]\n",
      "range_hood (29/40): 100%|██████████| 115/115 [00:00<00:00, 506664.87it/s]\n",
      "sink (30/40): 100%|██████████| 128/128 [00:00<00:00, 483232.14it/s]\n",
      "sofa (31/40): 100%|██████████| 680/680 [00:00<00:00, 433124.79it/s]\n",
      "stairs (32/40): 100%|██████████| 124/124 [00:00<00:00, 548622.04it/s]\n",
      "stool (33/40): 100%|██████████| 90/90 [00:00<00:00, 489607.47it/s]\n",
      "table (34/40): 100%|██████████| 392/392 [00:00<00:00, 548238.47it/s]\n",
      "tent (35/40): 100%|██████████| 163/163 [00:00<00:00, 479097.09it/s]\n",
      "toilet (36/40): 100%|██████████| 344/344 [00:00<00:00, 549653.55it/s]\n",
      "tv_stand (37/40): 100%|██████████| 267/267 [00:00<00:00, 503996.03it/s]\n",
      "vase (38/40): 100%|██████████| 475/475 [00:00<00:00, 566797.84it/s]\n",
      "wardrobe (39/40): 100%|██████████| 87/87 [00:00<00:00, 521292.07it/s]\n",
      "xbox (40/40): 100%|██████████| 103/103 [00:00<00:00, 434621.04it/s]\n",
      "airplane (1/40): 100%|██████████| 100/100 [00:00<00:00, 482658.69it/s]\n",
      "bathtub (2/40): 100%|██████████| 50/50 [00:00<00:00, 447153.94it/s]\n",
      "bed (3/40): 100%|██████████| 100/100 [00:00<00:00, 429304.40it/s]\n",
      "bench (4/40): 100%|██████████| 20/20 [00:00<00:00, 328965.02it/s]\n",
      "bookshelf (5/40): 100%|██████████| 100/100 [00:00<00:00, 532272.08it/s]\n",
      "bottle (6/40): 100%|██████████| 100/100 [00:00<00:00, 180555.49it/s]\n",
      "bowl (7/40): 100%|██████████| 20/20 [00:00<00:00, 334207.49it/s]\n",
      "car (8/40): 100%|██████████| 100/100 [00:00<00:00, 502914.15it/s]\n",
      "chair (9/40): 100%|██████████| 100/100 [00:00<00:00, 429304.40it/s]\n",
      "cone (10/40): 100%|██████████| 20/20 [00:00<00:00, 185588.67it/s]\n",
      "cup (11/40): 100%|██████████| 20/20 [00:00<00:00, 317750.30it/s]\n",
      "curtain (12/40): 100%|██████████| 20/20 [00:00<00:00, 298526.98it/s]\n",
      "desk (13/40): 100%|██████████| 86/86 [00:00<00:00, 512372.36it/s]\n",
      "door (14/40): 100%|██████████| 20/20 [00:00<00:00, 384798.53it/s]\n",
      "dresser (15/40): 100%|██████████| 86/86 [00:00<00:00, 517518.14it/s]\n",
      "flower_pot (16/40): 100%|██████████| 20/20 [00:00<00:00, 316551.25it/s]\n",
      "glass_box (17/40): 100%|██████████| 100/100 [00:00<00:00, 425817.66it/s]\n",
      "guitar (18/40): 100%|██████████| 100/100 [00:00<00:00, 515270.76it/s]\n",
      "keyboard (19/40): 100%|██████████| 20/20 [00:00<00:00, 369542.20it/s]\n",
      "lamp (20/40): 100%|██████████| 20/20 [00:00<00:00, 356962.04it/s]\n",
      "laptop (21/40): 100%|██████████| 20/20 [00:00<00:00, 349525.33it/s]\n",
      "mantel (22/40): 100%|██████████| 100/100 [00:00<00:00, 425817.66it/s]\n",
      "monitor (23/40): 100%|██████████| 100/100 [00:00<00:00, 526261.48it/s]\n",
      "night_stand (24/40): 100%|██████████| 86/86 [00:00<00:00, 405748.19it/s]\n",
      "person (25/40): 100%|██████████| 20/20 [00:00<00:00, 338250.32it/s]\n",
      "piano (26/40): 100%|██████████| 100/100 [00:00<00:00, 517815.31it/s]\n",
      "plant (27/40): 100%|██████████| 100/100 [00:00<00:00, 448588.66it/s]\n",
      "radio (28/40): 100%|██████████| 20/20 [00:00<00:00, 349525.33it/s]\n",
      "range_hood (29/40): 100%|██████████| 100/100 [00:00<00:00, 523633.46it/s]\n",
      "sink (30/40): 100%|██████████| 20/20 [00:00<00:00, 327680.00it/s]\n",
      "sofa (31/40): 100%|██████████| 100/100 [00:00<00:00, 432402.47it/s]\n",
      "stairs (32/40): 100%|██████████| 20/20 [00:00<00:00, 327680.00it/s]\n",
      "stool (33/40): 100%|██████████| 20/20 [00:00<00:00, 327680.00it/s]\n",
      "table (34/40): 100%|██████████| 100/100 [00:00<00:00, 423667.07it/s]\n",
      "tent (35/40): 100%|██████████| 20/20 [00:00<00:00, 339619.76it/s]\n",
      "toilet (36/40): 100%|██████████| 100/100 [00:00<00:00, 492289.20it/s]\n",
      "tv_stand (37/40): 100%|██████████| 100/100 [00:00<00:00, 416514.80it/s]\n",
      "vase (38/40): 100%|██████████| 100/100 [00:00<00:00, 526261.48it/s]\n",
      "wardrobe (39/40): 100%|██████████| 20/20 [00:00<00:00, 316551.25it/s]\n",
      "xbox (40/40): 100%|██████████| 20/20 [00:00<00:00, 317750.30it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = load_modelnet40(\"data/ModelNet40_2\")\n",
    "test_dl = DataLoader(test_ds, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(true_labels, predicted_labels):\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    recall = recall_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='weighted', zero_division=0)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def compute_test_metrics(model, test_dl):\n",
    "    model.eval()\n",
    "    \n",
    "    trues = []\n",
    "    preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dl):\n",
    "            x = batch[\"pointcloud\"].float().to('mps')\n",
    "            y = batch[\"category\"].to(\"mps\")\n",
    "\n",
    "            # Assuming model returns probabilities, you might need to convert them to classes.\n",
    "            pred_probabilities = model(x)\n",
    "            pred_classes = pred_probabilities.argmax(dim=1)\n",
    "\n",
    "            trues.extend(y.cpu().numpy())\n",
    "            preds.extend(pred_classes.cpu().numpy())\n",
    "\n",
    "    print(trues)\n",
    "    print(preds)\n",
    "\n",
    "    accuracy, precision, recall, f1 = compute_metrics(trues, preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('src/train')\n",
    "\n",
    "from train_model import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [04:45<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044165316045380876 0.042601391588757025 0.044165316045380876 0.04268158010120023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [04:22<00:00,  3.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044975688816855756 0.03304237331766346 0.044975688816855756 0.03710854998276379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 39/78 [02:56<02:56,  4.52s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(fp)\n\u001b[1;32m     26\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n\u001b[0;32m---> 28\u001b[0m accuracy, precision, recall, f1 \u001b[39m=\u001b[39m compute_test_metrics(model, test_dl)\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(accuracy, precision, recall, f1)\n",
      "Cell \u001b[0;32mIn[23], line 18\u001b[0m, in \u001b[0;36mcompute_test_metrics\u001b[0;34m(model, test_dl)\u001b[0m\n\u001b[1;32m     15\u001b[0m preds \u001b[39m=\u001b[39m []\n\u001b[1;32m     17\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(test_dl):\n\u001b[1;32m     19\u001b[0m         x \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mpointcloud\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m         y \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mmps\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/sys_genai/lib/python3.9/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sys_genai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/sys_genai/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/sys_genai/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/sys_genai/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/Documents/point-transformer-cardinality-reduction/src/dataset/modelnet40.py:136\u001b[0m, in \u001b[0;36mPointCloudData.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    134\u001b[0m category \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfiles[idx][\u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(pcd_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 136\u001b[0m     pointcloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__preproc__(f)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mpointcloud\u001b[39m\u001b[39m'\u001b[39m: pointcloud, \n\u001b[1;32m    138\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcategory\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses[category]}\n",
      "File \u001b[0;32m~/Documents/point-transformer-cardinality-reduction/src/dataset/modelnet40.py:127\u001b[0m, in \u001b[0;36mPointCloudData.__preproc__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__preproc__\u001b[39m(\u001b[39mself\u001b[39m, file):\n\u001b[0;32m--> 127\u001b[0m     verts, faces \u001b[39m=\u001b[39m read_off(file)\n\u001b[1;32m    128\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m    129\u001b[0m         pointcloud \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms((verts, faces))\n",
      "File \u001b[0;32m~/Documents/point-transformer-cardinality-reduction/src/dataset/modelnet40.py:29\u001b[0m, in \u001b[0;36mread_off\u001b[0;34m(file)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     n_verts, n_faces, __ \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m off_header[\u001b[39m3\u001b[39m:]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[0;32m---> 29\u001b[0m verts \u001b[39m=\u001b[39m [[\u001b[39mfloat\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)] \u001b[39mfor\u001b[39;00m i_vert \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_verts)]\n\u001b[1;32m     30\u001b[0m faces \u001b[39m=\u001b[39m [[\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)][\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m i_face \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_faces)]\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m verts, faces\n",
      "File \u001b[0;32m~/Documents/point-transformer-cardinality-reduction/src/dataset/modelnet40.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     n_verts, n_faces, __ \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m off_header[\u001b[39m3\u001b[39m:]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[0;32m---> 29\u001b[0m verts \u001b[39m=\u001b[39m [[\u001b[39mfloat\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)] \u001b[39mfor\u001b[39;00m i_vert \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_verts)]\n\u001b[1;32m     30\u001b[0m faces \u001b[39m=\u001b[39m [[\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)][\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m i_face \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_faces)]\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m verts, faces\n",
      "File \u001b[0;32m~/Documents/point-transformer-cardinality-reduction/src/dataset/modelnet40.py:29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     28\u001b[0m     n_verts, n_faces, __ \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m off_header[\u001b[39m3\u001b[39m:]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)])\n\u001b[0;32m---> 29\u001b[0m verts \u001b[39m=\u001b[39m [[\u001b[39mfloat\u001b[39;49m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)] \u001b[39mfor\u001b[39;00m i_vert \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_verts)]\n\u001b[1;32m     30\u001b[0m faces \u001b[39m=\u001b[39m [[\u001b[39mint\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m file\u001b[39m.\u001b[39mreadline()\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)][\u001b[39m1\u001b[39m:] \u001b[39mfor\u001b[39;00m i_face \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_faces)]\n\u001b[1;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m verts, faces\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "hidden_size = 64\n",
    "k = 32\n",
    "\n",
    "strat2name = {\n",
    "    \"1\": \"normal\",\n",
    "    \"2\": \"tome_ft\",\n",
    "    \"3\": \"tome_xyz\",\n",
    "    \"4\": \"random\"\n",
    "}\n",
    "\n",
    "for strat in strat2name:\n",
    "    model, _ = get_model(\n",
    "        \"pct\", \n",
    "        strat2name[strat], \n",
    "        1024,\n",
    "        40,\n",
    "        3,\n",
    "        hidden_size,\n",
    "        k,  \n",
    "        \"mps\"\n",
    "    )\n",
    "    model.to(\"mps\")\n",
    "\n",
    "    fp = os.path.join(\"outputs/test\", strat, \"model.pt\")\n",
    "    state_dict = torch.load(fp)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    accuracy, precision, recall, f1 = compute_test_metrics(model, test_dl)\n",
    "    print(accuracy, precision, recall, f1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCT(\n",
      "  (conv1): Conv1d(3, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (downsample1): FPS_KNN_PCT(\n",
      "    (sample_and_group): Sample_Group()\n",
      "    (local_op): Local_op(\n",
      "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (downsample2): FPS_KNN_PCT(\n",
      "    (sample_and_group): Sample_Group()\n",
      "    (local_op): Local_op(\n",
      "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pt_last): StackedAttention(\n",
      "    (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (sa1): SA_Layer(\n",
      "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "    (sa2): SA_Layer(\n",
      "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "    (sa3): SA_Layer(\n",
      "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "    (sa4): SA_Layer(\n",
      "      (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "      (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
      "      (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (act): ReLU()\n",
      "      (softmax): Softmax(dim=-1)\n",
      "    )\n",
      "    (relu): ReLU()\n",
      "  )\n",
      "  (relu): ReLU()\n",
      "  (conv_fuse): Sequential(\n",
      "    (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (linear1): Linear(in_features=1024, out_features=512, bias=False)\n",
      "  (bn6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dp1): Dropout(p=0.5, inplace=False)\n",
      "  (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (bn7): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dp2): Dropout(p=0.5, inplace=False)\n",
      "  (linear3): Linear(in_features=256, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hidden_size = 64\n",
    "k = 32\n",
    "\n",
    "model, _ = get_model(\n",
    "    \"pct\", \n",
    "    \"normal\", \n",
    "    1024,\n",
    "    40,\n",
    "    3,\n",
    "    hidden_size,\n",
    "    k,  \n",
    "    \"mps\"\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "fp = os.path.join(\"outputs/test\", \"1\", \"model.pt\")\n",
    "state_dict = torch.load(fp)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sys_genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
